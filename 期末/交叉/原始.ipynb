{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb99d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, set_seed\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 定义超参数\n",
    "BATCH_SIZE = 32  # 批处理大小\n",
    "EPOCHS = 70  # 迭代次数\n",
    "MAX_LENGTH = 40  # 序列最大长度\n",
    "LEARNING_RATE = 5e-5  # 学习率\n",
    "WEIGHT_DECAY = 0.01  # 权重衰减系数\n",
    "NUM_WARMUP_STEPS = 1000  # 热身步骤数\n",
    "MODEL_NAME = 'bert-base-chinese'  # 预训练模型名\n",
    "N_FOLDS = 5  # 交叉验证折数\n",
    "RANDOM_STATE = 42  # 随机种子\n",
    "\n",
    "# 设置随机种子，保证结果可复现\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# 加载csv数据集，数据路径为'train_dataset.csv'\n",
    "raw_dataset = load_dataset('csv', data_files='train_dataset.csv', split='train')\n",
    "\n",
    "# 对标签进行编码，将类别标签转化为数字\n",
    "raw_dataset = raw_dataset.class_encode_column('label')\n",
    "\n",
    "# 从预训练模型名加载Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 定义编码函数，对输入的文本进行编码\n",
    "def encode(examples):\n",
    "    return tokenizer(examples['query'], truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
    "\n",
    "# 对数据集进行编码\n",
    "raw_dataset = raw_dataset.map(encode, batched=True, remove_columns='#')\n",
    "\n",
    "# 创建交叉验证对象\n",
    "cross_validator = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "# 进行交叉验证\n",
    "for fold, (train_indices, valid_indices) in enumerate(cross_validator.split(raw_dataset)):\n",
    "    # 划分训练集和验证集\n",
    "    train_subset = raw_dataset.select(train_indices)\n",
    "    valid_subset = raw_dataset.select(valid_indices)\n",
    "\n",
    "    # 设置数据格式，用于训练模型\n",
    "    train_subset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    valid_subset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 准备模型，优化器和学习率调度器\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=train_subset.features['label'].num_classes)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=LEARNING_RATE, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "\n",
    "    # 进行模型训练\n",
    "    best_acc = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            # 模型前向传播，计算loss\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            # 反向传播，更新梯度\n",
    "            loss.backward()\n",
    "\n",
    "            # 优化器步进，更新模型参数\n",
    "            optimizer.step()\n",
    "            # 更新学习率\n",
    "            scheduler.step()\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.detach().item()\n",
    "\n",
    "        # 验证模型，计算验证集上的精度\n",
    "        model.eval()\n",
    "        valid_predictions = []\n",
    "        for batch in valid_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            valid_predictions.extend(outputs.logits.argmax(-1).cpu().numpy())\n",
    "\n",
    "        valid_acc = np.mean(valid_predictions == valid_subset['label'].numpy())\n",
    "        print(f\"Fold: {fold+1}, Epoch: {epoch+1}, Train Loss: {total_loss:.3f}, Validation Accuracy: {valid_acc:.4f}\")\n",
    "\n",
    "        # 保存在验证集上最好的结果\n",
    "        if valid_acc >= best_acc:\n",
    "            model.save_pretrained('output')\n",
    "\n",
    "    # 加载测试数据集，对测试集进行预测\n",
    "    test_dataset = load_dataset('csv', data_files='test_dataset.csv', split='train')\n",
    "    test_id = test_dataset['id']\n",
    "    test_dataset = test_dataset.map(encode, batched=True, remove_columns='id')\n",
    "    test_dataset.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('output')\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        predictions.extend(outputs.logits.argmax(-1).cpu().numpy())\n",
    "\n",
    "    # 将预测的标签从数字转换回原始的类别\n",
    "    predicted_labels = train_subset.features['label'].int2str(predictions)\n",
    "\n",
    "    # 保存预测结果，以csv格式存储\n",
    "    submission = pd.DataFrame({'id': test_id, 'label': predicted_labels})\n",
    "    submission.to_csv(f'submit_sample_fold_{fold+1}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa8994-730d-45be-81e9-be5f1d784495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
